{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "22666bca-72d0-4dbd-8a0b-ae44ce05cfcb"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.dates as mdates\n",
    "plt.style.use('ggplot') \n",
    "import calendar\n",
    "import quandl\n",
    "import pickle\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "import re  \n",
    "import psycopg2\n",
    "import sys\n",
    "import matplotlib.gridspec as gridspec\n",
    "import sqlalchemy\n",
    "from sqlalchemy.sql import select, and_, or_, not_, desc, asc\n",
    "from sqlalchemy import Table, Column, Integer, DateTime, String,Float, ForeignKey\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "ca01e3fc-afd9-4109-b059-285cde48db1e"
    }
   },
   "outputs": [],
   "source": [
    "def connect(user, password, db, host='localhost', port=5432):\n",
    "    '''Returns a connection and a metadata object'''\n",
    "    # We connect with the help of the PostgreSQL URL\n",
    "    url = 'postgresql+psycopg2://{}:{}@{}:{}/{}'\n",
    "    url = url.format(user, password, host, port, db)\n",
    "\n",
    "    # The return value of create_engine() is our connection object\n",
    "    con = sqlalchemy.create_engine(url, client_encoding='utf8')\n",
    "\n",
    "    # We then bind the connection to MetaData()\n",
    "    meta = sqlalchemy.MetaData(bind=con)\n",
    "\n",
    "    return con, meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "cfc1da92-5152-4cbe-83dc-06f086a99735"
    }
   },
   "source": [
    "CREATE TABLES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c3b31811-accd-4e26-b82d-04e60343335f"
    }
   },
   "outputs": [],
   "source": [
    "con, meta = connect('postgres', '', 'robotdb')\n",
    "\n",
    "mkt_trend = Table('Market_trend', meta,\n",
    "                      Column('coin', String, primary_key=True),\n",
    "                      Column('date', DateTime, primary_key=True),\n",
    "                      Column('screen', Integer, primary_key=True),\n",
    "                      Column('dif_current', Float),\n",
    "                      Column('dif_base', Float),\n",
    "                      Column('d_dif', Float),\n",
    "                      Column('theta_current', Float),\n",
    "                      Column('theta_base', Float),\n",
    "                      Column('d_theta', Float),\n",
    "                      Column('long_dif', Float),\n",
    "                      Column('max_growth', Float),\n",
    "                      Column('max_loss', Float),\n",
    "                      Column('max_price', Float),\n",
    "                      Column('min_price', Float),\n",
    "                      Column('max_rel', Float),\n",
    "                      Column('min_rel', Float),\n",
    "                      Column('log_ret', Float),\n",
    "                      Column('log_ret_p', Float),\n",
    "                      Column('log_ret_t_1', Float),\n",
    "                      Column('histogram', Float),\n",
    "                      Column('ema_dif', Float),\n",
    "                      Column('rsi', Float),\n",
    "                      Column('dif_sma', Float),\n",
    "                      Column('max_growth_p', Float),\n",
    "                      Column('obv', Float),\n",
    "                      Column('strength', Float),\n",
    "                      Column('vote', Integer)\n",
    "                      )\n",
    "\n",
    "tickers = Table('Ticker', meta,\n",
    "    Column('date', DateTime, primary_key = True),\n",
    "    Column('coin', String, primary_key = True),\n",
    "    Column('price', Float),\n",
    "    Column('volume', Float),\n",
    "    Column('screen', String, primary_key = True)    \n",
    ")\n",
    "\n",
    "years = mdates.YearLocator()   # every year\n",
    "months = mdates.MonthLocator()  # every month\n",
    "yearsFmt = mdates.DateFormatter('%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "8b5ada16-9c1a-403b-9ccb-01c08535beda"
    }
   },
   "outputs": [],
   "source": [
    "def get_mkt_trend(coin=None, date='2019-12-31', screen=1):\n",
    "    if coin:\n",
    "        s = select([mkt_trend]).\\\n",
    "            where(and_(mkt_trend.c.coin == coin, mkt_trend.c.date <= date, mkt_trend.c.screen == screen)).\\\n",
    "            order_by(desc(mkt_trend.c.date))\n",
    "    else:\n",
    "        s = select([mkt_trend]).\\\n",
    "            where(and_(mkt_trend.c.date <= date, mkt_trend.c.screen == screen)).\\\n",
    "            order_by(desc(mkt_trend.c.date))\n",
    "    rows = con.execute(s)\n",
    "    mkt_trend_df = pd.DataFrame(rows.fetchall()).iloc[::-1]\n",
    "    mkt_trend_df.columns = rows.keys()\n",
    "    return mkt_trend_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_df(train, test, scale_columns):\n",
    "    # #STANDARD SCALER\n",
    "    scaler = preprocessing.StandardScaler().fit(train[scale_columns])\n",
    "    train[scale_columns] = scaler.transform(train[scale_columns])\n",
    "    test[scale_columns] = scaler.transform(test[scale_columns])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FETCH DATA FROM DATABASE AND JOIN TABLES \n",
    "MKTTREND - PRICE - MACDS - RSI - SMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "107dfb91-c426-4580-89e0-f3f92403f2f1"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def manipulate_mkt_data():\n",
    "    df_model = get_mkt_trend()\n",
    "    df_model = df_model.drop(['max_growth_p'], axis=1).dropna()\n",
    "    df_model.loc[df_model['max_growth'] >= 0.1, 'growth_sign'] = 1\n",
    "    df_model.loc[df_model['max_growth'] < 0.1, 'growth_sign'] = 0\n",
    "    dates_ = df_model[['date']]\n",
    "    shifted_parms = df_model[['coin', 'max_growth']].shift(1)\n",
    "    shifted_parms['date'] = dates_\n",
    "    df_model = pd.merge(df_model, shifted_parms, how='inner', left_on=['date', 'coin'], right_on=['date', 'coin'])\n",
    "    df_model['max_growth'] = df_model['max_growth_x']\n",
    "    df_model['max_growth_p'] = df_model['max_growth_y']\n",
    "    df_model = df_model.drop(['max_growth_x', 'max_growth_y'], axis=1)\n",
    "    df_model = df_model.dropna()\n",
    "    df_model = df_model.sort_values(['date'])\n",
    "    df = df_model.drop(['screen', 'max_growth'] ,axis=1)\n",
    "    return df\n",
    "    \n",
    "df_model = manipulate_mkt_data()\n",
    "df_model['strength_ema'] = df_model.strength.ewm(span=6,min_periods=6,adjust=True,ignore_na=False).mean()\n",
    "df_model = df_model.dropna()\n",
    "df_model = df_model.sort_values(['date']).reset_index().drop(['index', 'date', 'coin', 'vote',\n",
    "                                                              'max_loss', 'max_price', 'min_price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_subset_cv(estimator, X_train, y_train, X_test, y_test):\n",
    "    from itertools import chain, combinations\n",
    "    n_features = X_train.shape[1]\n",
    "    subsets = chain.from_iterable(combinations(range(k), k + 1)\n",
    "                                  for k in range(n_features))\n",
    "    result = []\n",
    "    for subset in subsets:\n",
    "        print(subset)\n",
    "        estimator.fit(X_train[:, subset], y_train)\n",
    "        Y_predict = estimator.predict(X_test[:, subset])\n",
    "        cm = confusion_matrix(y_test,Y_predict)\n",
    "        result.append({\n",
    "            \"precision\": float(cm[1][1]/(cm[1][1]+cm[0][1])),\n",
    "            \"feat\": subset,\n",
    "            \"parms\": model.best_params_\n",
    "        })\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_model\n",
    "train = df.iloc[0:math.floor(len(df)*0.75)].copy()\n",
    "test = df.iloc[math.floor(len(df)*0.75):len(df)].copy()\n",
    "\n",
    "X_train, y_train = train.drop(['growth_sign'], axis=1), train.growth_sign.values\n",
    "X_test, y_test =  test.drop(['growth_sign'], axis=1), test.growth_sign.values\n",
    "oversampler = SMOTE(random_state=42)\n",
    "X_train_os, Y_train_os = oversampler.fit_sample(X_train,y_train)\n",
    "\n",
    "param_grid = {'max_depth': np.arange(1, 20), 'min_samples_leaf':np.arange(1, 8),}\n",
    "model = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_subset_cv(model, X_train_os, Y_train_os, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "n_features = X_train_os.shape[1]\n",
    "subsets = chain.from_iterable(combinations(range(k), k + 1) for k in range(n_features))\n",
    "for subset in subsets:\n",
    "    print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.chain at 0x7f1c7a5ec048>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain, combinations\n",
    "n_features = 10\n",
    "s = chain.from_iterable(combinations(range(k), k + 1) for k in range(n_features))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
